{
  "name": "Analyzing Northeastern's Crime Log",
  "tagline": "Bostonography Final Project - Dan Rhim & Tevin Otieno",
  "body": "### Introduction\r\nCampus safety is a crucially important yet often overlooked part of college life. Especially once students are already in university, safety is often discussed big-picture. It's not uncommon to hear platitudes like \"Columbus Ave is sketchy at night\". Our project aims to quantitatively explore crime and safety on Northeastern University's campus by analyzing data from the Northeastern University Police Department incident reports. \r\n\r\n### Data Collection\r\nHuntington News, Northeastern's campus paper, publishes a weekly \"Crime Log\" with select incident reports throughout the week. These are available [online](http://huntnewsnu.com/category/crime-log/) dating back to 2002. Initially, we intended to scrape the data off Northeastern's website, but we quickly scrapped that idea due to the inconsistent formatting and difficulty involved in accurately parsing the logs. \r\nWe decided to reach out to NUPD and request a digital copy of the data. After an office visit and a few not-so-frictionless phone calls, they sent over incident reports from 1st Jan 2016 to  2nd Dec 2016. \r\nThe reports were in a pdf, which we used [tabula](https://github.com/tabulapdf/tabula) and a python script to extract into a usable CSV. \r\n\r\n### Incidents\r\nThe first thing we explored was the different _types_ of incident reports. \r\n```{r}\r\ntab <- table(logs$INCIDENT)\r\nlogsCorpus <- Corpus(VectorSource(logs$INCIDENT))\r\nlogsCorpus <- tm_map(logsCorpus, PlainTextDocument)\r\npng(\"wordcloud.png\", width=1280,height=800)\r\nwordcloud(names(tab),as.numeric(tab),scale = c(1, 0.5), random.order = FALSE, colors=brewer.pal(9, \"Set1\"))\r\n```\r\n\r\n```{python}\r\ndf3 = pd.read_csv(\"{CSV FILE}\", sep=\";\")\r\nsplits = df3['INCIDENT'].str.split(' - ')\r\ndf3['INCIDENT_MIN'] = splits.str[0]\r\ndf3 = pd.crosstab(df3['LOCATION'], df3['INCIDENT_MIN'])\r\n\r\ndf3['TOTAL_COL'] = df3.sum(axis=1)\r\ndf3.sort_values(by='TOTAL_COL', axis=0, inplace=True, ascending=False)\r\ndf3 = df3.head(n=25)\r\ndf3.drop('TOTAL_COL', axis=1, inplace=True)\r\n\r\nfig, ax = plt.subplots()\r\nheatmap = ax.pcolor(df3, cmap=plt.cm.Blues, alpha=5)\r\n\r\nfig = plt.gcf()\r\nax.set_frame_on(False)\r\nax.set_yticks(np.arange(df3.shape[0])+0.5, minor=False)\r\nax.set_xticks(np.arange(df3.shape[1])+0.5, minor=False)\r\nax.set_xticklabels(df3.columns, minor=False)\r\nax.set_yticklabels(df3.index, minor=False)\r\n\r\nax.invert_yaxis()\r\nax.xaxis.tick_top()\r\n\r\nplt.xticks(rotation=90)\r\n\r\nax = plt.gca()\r\nfor t in ax.xaxis.get_major_ticks(): \r\n    t.tick1On = False \r\n    t.tick2On = False \r\nfor t in ax.yaxis.get_major_ticks(): \r\n    t.tick1On = False \r\n    t.tick2On = False  \r\n```\r\n\r\n![Heatmap](http://i.imgur.com/yRfn1px.png)\r\nWe also made a heatmap to visualize the frequency of specific incidents at the most reported locations. Larceny, Medical and Suspicious Activity are the most frequent type of incidents across all the locations. \r\nAlso of note, is \"Larceny\" is most frequently reported at Marino Center and Snell Library, which are studying hotspots that are often targets for theft. \r\n\r\n### Time\r\nWe also looked at _when_ these reports occur\r\nFirst, we looked at frequency at each hour over the day.\r\n\r\n```{python}\r\ndf = pd.read_csv(\"{CSV_FILE}\", sep=\";\", parse_dates=['DATE'], date_parser=date_parser)\r\ndf = df.set_index(pd.DatetimeIndex(df['DATE']))\r\nfreq_hour = df.resample('H').count()\r\nfreq_hour\r\nfig, ax = plt.subplots(1, 1)\r\nax.plot(freq_hour['DATE'])\r\nax.xaxis_date()\r\nfig.autofmt_xdate()\r\n```\r\n![Frequency Day](http://i.imgur.com/psVItBj.png)\r\n\r\nAs expected, the \"busiest\" hours are at night, starting around 10PM and peaking at 1AM, with a steady drop until the early morning, which boasts the least number of reports.\r\n\r\nWe also looked at daily number of reports over the entire year\r\n![Frequency Year](http://i.imgur.com/XuLzU4g.png)\r\n\r\nThere's a huge spike in reports around the end of March/Beginning of April, which we thought might align with the nice weather and the end of midterm season. \r\nThere's a lull in the summer, as there's usually less people on campus around that time. Another spike occurs at the beginning of the semester around September, when everyone is back on campus. \r\n\r\n### Challenges\r\nOur biggest challenge was getting the data into the desired format. We got the data as a pdf file from NUPD, which proved more inconvenient that we had thought.\r\nWe became intimately familiar with pdf layout and formatting standards (or lack thereof) and spent a lot of time tweaking our parser to correctly scrape the data. This slowed down our progress immensely because it blocked progress on the analysis itself. \r\n\r\nOur other big challenge was the unavailability of data from other schools. We excitedly considered doing similar analyses on other local universities, but we were unable to get a hold of any useful datasets, with the notable exception of MIT. \r\n\r\n### Blue Sky\r\nGiven unlimited funds and time, there's a few angles we'd love to explore with this project\r\n1. Look at other local universities' safety reports. Compare incidence frequency and time.\r\n2. Join NUPD data with BPD and explore the difference in types and frequency of reports made to BPD around Northeastern\r\n3. Visualize locations with an actual heatmap, overlaid over a map of Boston. \r\n4. Add interactivity to enable specific analysis across the different data types.\r\n\r\n### Authors and Contributors\r\nDan Rhim & Tevin Otieno\r\n\r\nP.S. For the sake of speed, we ended up doing analysis in both Python and R, depending on technical ability and ease of use.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}