<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=640">

    <link rel="stylesheet" href="stylesheets/core.css" media="screen">
    <link rel="stylesheet" href="stylesheets/mobile.css" media="handheld, only screen and (max-device-width:640px)">
    <link rel="stylesheet" href="stylesheets/github-light.css">

    <script type="text/javascript" src="javascripts/modernizr.js"></script>
    <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script type="text/javascript" src="javascripts/headsmart.min.js"></script>
    <script type="text/javascript">
      $(document).ready(function () {
        $('#main_content').headsmart()
      })
    </script>
    <title>Analyzing Northeastern&#39;s Crime Log by motevin</title>
  </head>

  <body>
    <a id="forkme_banner" href="https://github.com/motevin/crime-log-analysis">View on GitHub</a>
    <div class="shell">

      <header>
        <span class="ribbon-outer">
          <span class="ribbon-inner">
            <h1>Analyzing Northeastern&#39;s Crime Log</h1>
            <h2>Bostonography Final Project - Dan Rhim &amp; Tevin Otieno</h2>
          </span>
          <span class="left-tail"></span>
          <span class="right-tail"></span>
        </span>
      </header>

      <section id="downloads">
        <span class="inner">
          <a href="https://github.com/motevin/crime-log-analysis/zipball/master" class="zip"><em>download</em> .ZIP</a><a href="https://github.com/motevin/crime-log-analysis/tarball/master" class="tgz"><em>download</em> .TGZ</a>
        </span>
      </section>


      <span class="banner-fix"></span>


      <section id="main_content">
        <h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h3>

<p>Campus safety is a crucially important yet often overlooked part of college life. Especially once students are already in university, safety is often discussed big-picture. It's not uncommon to hear platitudes like "Columbus Ave is sketchy at night". Our project aims to quantitatively explore crime and safety on Northeastern University's campus by analyzing data from the Northeastern University Police Department incident reports. </p>

<h3>
<a id="data-collection" class="anchor" href="#data-collection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data Collection</h3>

<p>Huntington News, Northeastern's campus paper, publishes a weekly "Crime Log" with select incident reports throughout the week. These are available <a href="http://huntnewsnu.com/category/crime-log/">online</a> dating back to 2002. Initially, we intended to scrape the data off Northeastern's website, but we quickly scrapped that idea due to the inconsistent formatting and difficulty involved in accurately parsing the logs. 
We decided to reach out to NUPD and request a digital copy of the data. After an office visit and a few not-so-frictionless phone calls, they sent over incident reports from 1st Jan 2016 to  2nd Dec 2016. 
The reports were in a pdf, which we used <a href="https://github.com/tabulapdf/tabula">tabula</a> and a python script to extract into a usable CSV. </p>

<h3>
<a id="incidents" class="anchor" href="#incidents" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Incidents</h3>

<p>The first thing we explored was the different <em>types</em> of incident reports. </p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">tab</span> <span class="pl-k">&lt;-</span> table(<span class="pl-smi">logs</span><span class="pl-k">$</span><span class="pl-smi">INCIDENT</span>)
<span class="pl-smi">logsCorpus</span> <span class="pl-k">&lt;-</span> Corpus(VectorSource(<span class="pl-smi">logs</span><span class="pl-k">$</span><span class="pl-smi">INCIDENT</span>))
<span class="pl-smi">logsCorpus</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">logsCorpus</span>, <span class="pl-smi">PlainTextDocument</span>)
png(<span class="pl-s"><span class="pl-pds">"</span>wordcloud.png<span class="pl-pds">"</span></span>, <span class="pl-v">width</span><span class="pl-k">=</span><span class="pl-c1">1280</span>,<span class="pl-v">height</span><span class="pl-k">=</span><span class="pl-c1">800</span>)
wordcloud(names(<span class="pl-smi">tab</span>),as.numeric(<span class="pl-smi">tab</span>),<span class="pl-v">scale</span> <span class="pl-k">=</span> c(<span class="pl-c1">1</span>, <span class="pl-c1">0.5</span>), <span class="pl-v">random.order</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>, <span class="pl-v">colors</span><span class="pl-k">=</span>brewer.pal(<span class="pl-c1">9</span>, <span class="pl-s"><span class="pl-pds">"</span>Set1<span class="pl-pds">"</span></span>))</pre></div>

<div class="highlight highlight-source-python"><pre>df3 <span class="pl-k">=</span> pd.read_csv(<span class="pl-s"><span class="pl-pds">"</span>{CSV FILE}<span class="pl-pds">"</span></span>, <span class="pl-v">sep</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>;<span class="pl-pds">"</span></span>)
splits <span class="pl-k">=</span> df3[<span class="pl-s"><span class="pl-pds">'</span>INCIDENT<span class="pl-pds">'</span></span>].str.split(<span class="pl-s"><span class="pl-pds">'</span> - <span class="pl-pds">'</span></span>)
df3[<span class="pl-s"><span class="pl-pds">'</span>INCIDENT_MIN<span class="pl-pds">'</span></span>] <span class="pl-k">=</span> splits.str[<span class="pl-c1">0</span>]
df3 <span class="pl-k">=</span> pd.crosstab(df3[<span class="pl-s"><span class="pl-pds">'</span>LOCATION<span class="pl-pds">'</span></span>], df3[<span class="pl-s"><span class="pl-pds">'</span>INCIDENT_MIN<span class="pl-pds">'</span></span>])

df3[<span class="pl-s"><span class="pl-pds">'</span>TOTAL_COL<span class="pl-pds">'</span></span>] <span class="pl-k">=</span> df3.sum(<span class="pl-v">axis</span><span class="pl-k">=</span><span class="pl-c1">1</span>)
df3.sort_values(<span class="pl-v">by</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>TOTAL_COL<span class="pl-pds">'</span></span>, <span class="pl-v">axis</span><span class="pl-k">=</span><span class="pl-c1">0</span>, <span class="pl-v">inplace</span><span class="pl-k">=</span><span class="pl-c1">True</span>, <span class="pl-v">ascending</span><span class="pl-k">=</span><span class="pl-c1">False</span>)
df3 <span class="pl-k">=</span> df3.head(<span class="pl-v">n</span><span class="pl-k">=</span><span class="pl-c1">25</span>)
df3.drop(<span class="pl-s"><span class="pl-pds">'</span>TOTAL_COL<span class="pl-pds">'</span></span>, <span class="pl-v">axis</span><span class="pl-k">=</span><span class="pl-c1">1</span>, <span class="pl-v">inplace</span><span class="pl-k">=</span><span class="pl-c1">True</span>)

fig, ax <span class="pl-k">=</span> plt.subplots()
heatmap <span class="pl-k">=</span> ax.pcolor(df3, <span class="pl-v">cmap</span><span class="pl-k">=</span>plt.cm.Blues, <span class="pl-v">alpha</span><span class="pl-k">=</span><span class="pl-c1">5</span>)

fig <span class="pl-k">=</span> plt.gcf()
ax.set_frame_on(<span class="pl-c1">False</span>)
ax.set_yticks(np.arange(df3.shape[<span class="pl-c1">0</span>])<span class="pl-k">+</span><span class="pl-c1">0.5</span>, <span class="pl-v">minor</span><span class="pl-k">=</span><span class="pl-c1">False</span>)
ax.set_xticks(np.arange(df3.shape[<span class="pl-c1">1</span>])<span class="pl-k">+</span><span class="pl-c1">0.5</span>, <span class="pl-v">minor</span><span class="pl-k">=</span><span class="pl-c1">False</span>)
ax.set_xticklabels(df3.columns, <span class="pl-v">minor</span><span class="pl-k">=</span><span class="pl-c1">False</span>)
ax.set_yticklabels(df3.index, <span class="pl-v">minor</span><span class="pl-k">=</span><span class="pl-c1">False</span>)

ax.invert_yaxis()
ax.xaxis.tick_top()

plt.xticks(<span class="pl-v">rotation</span><span class="pl-k">=</span><span class="pl-c1">90</span>)

ax <span class="pl-k">=</span> plt.gca()
<span class="pl-k">for</span> t <span class="pl-k">in</span> ax.xaxis.get_major_ticks(): 
    t.tick1On <span class="pl-k">=</span> <span class="pl-c1">False</span> 
    t.tick2On <span class="pl-k">=</span> <span class="pl-c1">False</span> 
<span class="pl-k">for</span> t <span class="pl-k">in</span> ax.yaxis.get_major_ticks(): 
    t.tick1On <span class="pl-k">=</span> <span class="pl-c1">False</span> 
    t.tick2On <span class="pl-k">=</span> <span class="pl-c1">False</span>  </pre></div>

<p><img src="http://i.imgur.com/yRfn1px.png" alt="Heatmap">
We also made a heatmap to visualize the frequency of specific incidents at the most reported locations. Larceny, Medical and Suspicious Activity are the most frequent type of incidents across all the locations. 
Also of note, is "Larceny" is most frequently reported at Marino Center and Snell Library, which are studying hotspots that are often targets for theft. </p>

<h3>
<a id="time" class="anchor" href="#time" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Time</h3>

<p>We also looked at <em>when</em> these reports occur
First, we looked at frequency at each hour over the day.</p>

<div class="highlight highlight-source-python"><pre>df <span class="pl-k">=</span> pd.read_csv(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-c1">{CSV_FILE}</span><span class="pl-pds">"</span></span>, <span class="pl-v">sep</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>;<span class="pl-pds">"</span></span>, <span class="pl-v">parse_dates</span><span class="pl-k">=</span>[<span class="pl-s"><span class="pl-pds">'</span>DATE<span class="pl-pds">'</span></span>], <span class="pl-v">date_parser</span><span class="pl-k">=</span>date_parser)
df <span class="pl-k">=</span> df.set_index(pd.DatetimeIndex(df[<span class="pl-s"><span class="pl-pds">'</span>DATE<span class="pl-pds">'</span></span>]))
freq_hour <span class="pl-k">=</span> df.resample(<span class="pl-s"><span class="pl-pds">'</span>H<span class="pl-pds">'</span></span>).count()
freq_hour
fig, ax <span class="pl-k">=</span> plt.subplots(<span class="pl-c1">1</span>, <span class="pl-c1">1</span>)
ax.plot(freq_hour[<span class="pl-s"><span class="pl-pds">'</span>DATE<span class="pl-pds">'</span></span>])
ax.xaxis_date()
fig.autofmt_xdate()</pre></div>

<p><img src="http://i.imgur.com/psVItBj.png" alt="Frequency Day"></p>

<p>As expected, the "busiest" hours are at night, starting around 10PM and peaking at 1AM, with a steady drop until the early morning, which boasts the least number of reports.</p>

<p>We also looked at daily number of reports over the entire year
<img src="http://i.imgur.com/XuLzU4g.png" alt="Frequency Year"></p>

<p>There's a huge spike in reports around the end of March/Beginning of April, which we thought might align with the nice weather and the end of midterm season. 
There's a lull in the summer, as there's usually less people on campus around that time. Another spike occurs at the beginning of the semester around September, when everyone is back on campus. </p>

<h3>
<a id="challenges" class="anchor" href="#challenges" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Challenges</h3>

<p>Our biggest challenge was getting the data into the desired format. We got the data as a pdf file from NUPD, which proved more inconvenient that we had thought.
We became intimately familiar with pdf layout and formatting standards (or lack thereof) and spent a lot of time tweaking our parser to correctly scrape the data. This slowed down our progress immensely because it blocked progress on the analysis itself. </p>

<p>Our other big challenge was the unavailability of data from other schools. We excitedly considered doing similar analyses on other local universities, but we were unable to get a hold of any useful datasets, with the notable exception of MIT. </p>

<h3>
<a id="blue-sky" class="anchor" href="#blue-sky" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Blue Sky</h3>

<p>Given unlimited funds and time, there's a few angles we'd love to explore with this project
1. Look at other local universities' safety reports. Compare incidence frequency and time.
2. Join NUPD data with BPD and explore the difference in types and frequency of reports made to BPD around Northeastern
3. Visualize locations with an actual heatmap, overlaid over a map of Boston. 
4. Add interactivity to enable specific analysis across the different data types.</p>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>Dan Rhim &amp; Tevin Otieno</p>

<p>P.S. For the sake of speed, we ended up doing analysis in both Python and R, depending on technical ability and ease of use.</p>
      </section>

      <footer>
        <span class="ribbon-outer">
          <span class="ribbon-inner">
            <p>this project by <a href="https://github.com/motevin">motevin</a> can be found on <a href="https://github.com/motevin/crime-log-analysis">GitHub</a></p>
          </span>
          <span class="left-tail"></span>
          <span class="right-tail"></span>
        </span>
        <p>Generated with <a href="https://pages.github.com">GitHub Pages</a> using Merlot</p>
        <span class="octocat"></span>
      </footer>

    </div>

    
  </body>
</html>
